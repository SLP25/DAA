{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pistachio - Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:12:23.733362230Z",
     "start_time": "2023-12-26T14:12:23.718300594Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data handling (arrays, matrices)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "RANDOM_SEED = 300721"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:47:02.927434821Z",
     "start_time": "2023-12-26T14:47:02.823132648Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "data = pd.read_excel('./dataset/Pistachio_16_Features_Dataset.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the perfect feature to predict:\n",
    "This dataset is filled with columns that have a direct correlation with each other. This, inevitably leads to good results if those are not removed. So, in order to avoid removing some tables (ranging from 3 to 5) we will instead choose the feature with less correlation with other columns in the dataset.\n",
    "\n",
    "To do this, we employ a correlation matrix between each and every attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DataFrame 'df_corr' by dropping the 'Class' column\n",
    "# Mapping class columns: 'Siit_Pistachio' to 0 and 'Kirmizi_Pistachio' to 1\n",
    "\n",
    "df_corr = data.drop(columns=['Class'])\n",
    "df_corr[\"Is_Siit\"] = data[\"Class\"].map({\"Siit_Pistachio\": 0, \"Kirmizi_Pistachio\": 1})\n",
    "\n",
    "corr_matrix = df_corr.corr(numeric_only=False)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(32, 32))\n",
    "sns.heatmap(corr_matrix, vmin=-1, square=True, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see on the above correlation heatmap, the feature '**EXTENT**' does not have any correlation above 66%, and thus is the chosen one to perform the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:50:39.691428600Z",
     "start_time": "2023-12-26T14:50:39.684121681Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assuming 'Area' is the target variable to predict and other features are used as predictors\n",
    "predictors = data.drop(['EXTENT', 'Class'], axis=1)  # Drop 'Area' and 'Class' columns\n",
    "target = data['EXTENT'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can perform some simple data analysis, in specific, relative to missing values and outliers. A deeper analysis is done on the classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do predictors have missing values ?\n",
    "predictors.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do predictors have duplicated values ?\n",
    "duplicate_count = predictors.duplicated().sum()\n",
    "display(duplicate_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do predictors have outliers ?\n",
    "numeric_columns = predictors.select_dtypes(include='number').columns\n",
    "\n",
    "# Create subplots for each numeric column\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(numeric_columns), figsize=(30, 5))\n",
    "\n",
    "# Iterate over numeric columns and create boxplots\n",
    "for i, column in enumerate(numeric_columns):\n",
    "    sns.boxplot(x=predictors[column], ax=axes[i], flierprops=dict(markerfacecolor='r', marker='D'))\n",
    "    axes[i].set_title(f'Boxplot for {column}')\n",
    "    axes[i].set_ylabel('Value')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Handling the outliers, by setting them as their closests allowed values\n",
    "from scipy import stats\n",
    "\n",
    "# Define a function to replace outliers with the nearest accepted value\n",
    "def replace_outliers_with_nearest_accepted_value(series):\n",
    "    # Calculate z-scores for each data point in the series\n",
    "    z_scores = np.abs(stats.zscore(series))\n",
    "    \n",
    "    # Identify outliers using a z-score threshold (3 in this case, but adjustable)\n",
    "    outliers = z_scores > 3\n",
    "    \n",
    "    # Extract non-outliers from the series\n",
    "    non_outliers = series[~outliers]\n",
    "    \n",
    "    # Define a function to find the nearest accepted value\n",
    "    def find_nearest_accepted_value(x):\n",
    "        return min(non_outliers, key=lambda v: abs(v - x))\n",
    "    \n",
    "    # Replace outliers with the nearest accepted value\n",
    "    series[outliers] = series[outliers].apply(find_nearest_accepted_value)\n",
    "    return series\n",
    "\n",
    "# Apply the replace_outliers_with_nearest_accepted_value function to every numeric column in the DataFrame\n",
    "for column in predictors.select_dtypes(include=[np.number]).columns:\n",
    "    predictors[column] = replace_outliers_with_nearest_accepted_value(predictors[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T15:02:11.150709130Z",
     "start_time": "2023-12-26T15:02:11.108889776Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Converting float64 features to float32 features\n",
    "for column in predictors.columns:\n",
    "    if predictors[column].dtype == 'float64':\n",
    "        predictors[column] = predictors[column].astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression\n",
    "\n",
    "For the first regression model, we are using a simple Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T15:36:44.359929012Z",
     "start_time": "2023-12-26T15:36:44.329008539Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_error\n",
    "\n",
    "# Splitting the data into training and testing sets (80% train, 20% test)\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# Initializing and training a Linear Regression model\n",
    "regression_model = LinearRegression(fit_intercept=True)\n",
    "regression_model.fit(predictors_train, target_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "target_pred = regression_model.predict(predictors_test)\n",
    "\n",
    "# Evaluating the model using metrics: MAE, MSE, RMSE\n",
    "mae = mean_absolute_error(target_test, target_pred)\n",
    "mse = mean_squared_error(target_test, target_pred)\n",
    "rmse = mean_squared_error(target_test, target_pred, squared=False)\n",
    "mape = np.mean(np.abs((target_test - target_pred) / target_pred)) * 100\n",
    "\n",
    "# Displaying the evaluation metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f} ({mape:.4f}%)\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we get great results out of the box, there's no need for hyperparameter tunning since linear regression doesn't really have any hyperparameters. \n",
    "\n",
    "4% as the error is great, but this value might be due to the correlations of the EXTENT with other features (such as the PERIMETER, SOLIDITY and SHAPEFACTOR_2), but after removing the columns with most correlation factor (>40%) the results obtained were the same within a range of .2%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting (XDGBoost)\n",
    "\n",
    "As for the second model, we are using an ensamble learning model, the XDGRegessor, while using grid search for hyperparameters tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# Define the parameter grid to search through\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.05, 0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "xgb_model = XGBRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model, \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    scoring='neg_mean_squared_error', \n",
    "    verbose=1, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(predictors_train, target_train)\n",
    "\n",
    "# Get the best parameters and the best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set using the best estimator\n",
    "target_pred = best_xgb.predict(predictors_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(target_test, target_pred)\n",
    "r2 = r2_score(target_test, target_pred)\n",
    "\n",
    "# Evaluating the model using metrics: MAE, MSE, RMSE\n",
    "mae = mean_absolute_error(target_test, target_pred)\n",
    "mse = mean_squared_error(target_test, target_pred)\n",
    "rmse = mean_squared_error(target_test, target_pred, squared=False)\n",
    "mape = np.mean(np.abs((target_test - target_pred) / target_pred)) * 100\n",
    "\n",
    "# Displaying the evaluation metrics\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f} ({mape:.4f}%)\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we get a small error (4.18%), pretty similar to the error obtained with linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result Analysis\n",
    "\n",
    "For both employed models, the error obtained is not very significant, this is due to the 'EXTENT' feature being obtained from a mathematical formula envolving other columns, this happens throughout a lot of other columns, and explains the great results. W\n",
    "\n",
    "As already stated above, removing the 'dependent' columns doesn't appear to affect the results, it will lead to, though, the loss of important and needed information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
